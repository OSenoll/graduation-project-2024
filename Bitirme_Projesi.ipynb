{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5QVpEnMOo1v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('cleaned_news_articles.csv')"
      ],
      "metadata": {
        "id": "EAGVv3-wVHa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "hqpllgb8VNlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "X3YReBYcVX67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "rQbFOvdgVltk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "HMzc5fx-Vzci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "IPMw8o75V2bR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "A6a13H_uWCPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_rows = data.isnull().any(axis=1)\n",
        "print(\"rows with missing values:\")\n",
        "print(missing_values_rows)"
      ],
      "metadata": {
        "id": "hCGq_MSqOywi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows = data[data.duplicated()]\n",
        "print(\"duplicate rows:\")\n",
        "print(duplicate_rows)"
      ],
      "metadata": {
        "id": "Zy241Z1sQtbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(axis=0, inplace = True)"
      ],
      "metadata": {
        "id": "eBebDy0SQ9Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values_rows = data.isnull().any(axis=1)\n",
        "print(\"rows with missing values:\")\n",
        "print(missing_values_rows)"
      ],
      "metadata": {
        "id": "xXphRrn6RHnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "tdCccpEiRQIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows = data[data.duplicated()]\n",
        "print(\"duplicate rows:\")\n",
        "print(duplicate_rows)"
      ],
      "metadata": {
        "id": "c6o39oANRXKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('cleaned_news_articles.csv', index=False)"
      ],
      "metadata": {
        "id": "bdjtaBG2RgVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('cleaned_news_articles.csv')"
      ],
      "metadata": {
        "id": "zUS0pBKiSOty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "x1bKfL5h5FNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_counts = data.groupby([\"site_url\",\"label\"]).size().unstack(fill_value=0)\n"
      ],
      "metadata": {
        "id": "wygJBRLd69Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_counts[\"Percentage Real (%)\"] = (source_counts[\"Real\"]/(source_counts[\"Real\"]+source_counts[\"Fake\"])) * 100\n",
        "source_counts[\"Percentage Fake (%)\"] = (source_counts[\"Fake\"]/(source_counts[\"Real\"]+source_counts[\"Fake\"])) * 100"
      ],
      "metadata": {
        "id": "BcQ0A_CG84wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_sources = source_counts.sort_values(by=\"Percentage Real (%)\", ascending=False)"
      ],
      "metadata": {
        "id": "xBhIeIiz9ecU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 10 Most Credible News Sources:\")\n",
        "for source, row in sorted_sources.head(10).iterrows():\n",
        "  print(f\"News {source}, fake news = {row['Percentage Fake (%)']:.1f}%\")\n",
        "\n",
        "print(\"Top 10 Least Credible News Sources:\")\n",
        "for source, row in sorted_sources.tail(10).iterrows():\n",
        "  print(f\"News {source}, fake news = {row['Percentage Fake (%)']:.1f}%\")"
      ],
      "metadata": {
        "id": "ND0x4Mmv8K7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Top 10 Most Credible News Sources\n",
        "top_10_credible = sorted_sources.head(10)\n",
        "# Top 10 Least Credible News Sources\n",
        "top_10_least_credible = sorted_sources.tail(10)\n",
        "\n",
        "# Grafik oluşturma\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# En güvenilir kaynaklar\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.barh(top_10_credible.index, top_10_credible['Percentage Fake (%)'], color='green')\n",
        "plt.xlabel('Sahte Haber Yüzdesi')\n",
        "plt.title('En Güvenilir 10 Kaynak')\n",
        "\n",
        "# En güvenilmez kaynaklar\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.barh(top_10_least_credible.index, top_10_least_credible['Percentage Fake (%)'], color='red')\n",
        "plt.xlabel('Sahte Haber Yüzdesi')\n",
        "plt.title('En Az Güvenilir 10 Kaynak')\n",
        "\n",
        "# Grafiklerin gösterilmesi\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SUw7xiKyO8A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "_FdNWgGr_bJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "pZct6Q1oAQSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wkICekxlEgWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from scipy.stats import chi2_contingency"
      ],
      "metadata": {
        "id": "nrhpYMA5E_SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "id": "SxMOVSAvA0GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_counter = Counter()\n",
        "text_counter = Counter()"
      ],
      "metadata": {
        "id": "2UgrpjpxAZb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in data.iterrows():\n",
        "  title_words = word_tokenize(row[\"title\"])\n",
        "  text_words = word_tokenize(row[\"text\"])\n",
        "\n",
        "  title_words = [word.lower() for word in title_words if word.isalpha() and word.lower() not in stop_words]\n",
        "  text_words = [word.lower() for word in title_words if word.isalpha() and word.lower() not in stop_words]\n",
        "\n",
        "  if row[\"label\"] == \"Fake\":\n",
        "    title_counter.update(title_words)\n",
        "    text_counter.update(text_words)"
      ],
      "metadata": {
        "id": "GeeFODsmBPiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_keywords_title = title_counter.most_common(5)\n",
        "top_keywords_text = text_counter.most_common(5)"
      ],
      "metadata": {
        "id": "N0a1HsnuBxoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Top 5 Keywords Associated with Fake News Titles:\")\n",
        "for keyword, count in top_keywords_title:\n",
        "  print(f\"{keyword}:{count} times\")\n",
        "print(\"Top 5 Keywords Associated with Fake News Texts:\")\n",
        "for keyword, count in top_keywords_text:\n",
        "  print(f\"{keyword}:{count} times\")"
      ],
      "metadata": {
        "id": "Q0K1HlfPAEt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"title_length\"] = data[\"title\"].apply(len)\n",
        "data[\"text_length\"] = data[\"text\"].apply(len)"
      ],
      "metadata": {
        "id": "RKEMENhDDTEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_news = data[data[\"label\"]==\"Real\"]\n",
        "fake_news = data[data[\"label\"]==\"Fake\"]"
      ],
      "metadata": {
        "id": "b1eHBn16DlUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_real_title_length = real_news[\"title_length\"].mean()\n",
        "avg_fake_title_length = fake_news[\"title_length\"].mean()\n",
        "avg_real_text_length = real_news[\"text_length\"].mean()\n",
        "avg_fake_text_length = fake_news[\"text_length\"].mean()"
      ],
      "metadata": {
        "id": "rwHU-Lm5DsD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Average Title Length for Real News: {avg_real_title_length:.2f} characters\")\n",
        "print(f\"Average Title Length for Fake News: {avg_fake_title_length:.2f} characters\")\n",
        "print(f\"Average Text Length for Real News: {avg_real_text_length:.2f} characters\")\n",
        "print(f\"Average Text Length for Fake News: {avg_fake_text_length:.2f} characters\")"
      ],
      "metadata": {
        "id": "5Eoe0QnOD7Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"Real Title\",\"Fake News\",\"Real Text\",\"Fake Text\"]\n",
        "lengths = [avg_real_title_length, avg_fake_title_length, avg_real_text_length,avg_fake_text_length ]"
      ],
      "metadata": {
        "id": "mxH8YwVxERJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(labels,lengths,color=[\"green\",\"red\",\"green\",\"red\"])\n",
        "plt.title(\"Average Title & Text Lengths for Real & Fake News\")\n",
        "plt.ylabel(\"Average Length (characters)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ipEOJn_0DFOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_sensationalism(text):\n",
        "    sensational_keywords = [\"shocking\", \"outrageous\", \"unbelievable\", \"mind-blowing\", \"explosive\"]\n",
        "\n",
        "    for keyword in sensational_keywords:\n",
        "        if re.search(r'\\b' + keyword + r'\\b', text, re.IGNORECASE):\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "tW6AUUSZFi7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "FQ_jnuqwG0w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Sensationalism\"] = data[\"text\"].apply(detect_sensationalism)"
      ],
      "metadata": {
        "id": "U6plYhO0FroZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contigency_table = pd.crosstab(data[\"Sensationalism\"],data[\"label\"])\n",
        "print(contigency_table)"
      ],
      "metadata": {
        "id": "YMOBT44B0hBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi2,p,_,_ = chi2_contingency(contigency_table)"
      ],
      "metadata": {
        "id": "TqeoPN0X0n_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Chi-squared statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")"
      ],
      "metadata": {
        "id": "az0Xze7q0t2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "  print(\"There is a significant association between sensationalism and credibility of the news\")\n",
        "else:\n",
        "  print(\"There is not significant association between sensationalism and credibility of the news\")"
      ],
      "metadata": {
        "id": "gB-iemd8FHDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "ElPg_vba1L_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "Mt8h7-qq1Wsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "eyI91A041bXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "  sentiment_score = analyzer.polarity_scores(text)\n",
        "  if sentiment_score[\"compound\"] >= 0.05:\n",
        "    return \"Positive\"\n",
        "  elif sentiment_score[\"compound\"] <= -0.05:\n",
        "    return \"Negative\"\n",
        "  else:\n",
        "    return \"Neutral\"\n",
        "\n",
        "data[\"Sentiment\"] = data[\"text\"].apply(analyze_sentiment)"
      ],
      "metadata": {
        "id": "KpEYjYGF1lci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data[['text','Sentiment']].head())"
      ],
      "metadata": {
        "id": "lpitm28k1NNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "qCZVamGr16LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_news_data = data[data['label'] == \"Fake\"]\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(fake_news_data[\"text\"])\n",
        "word_frequencies = X.toarray().sum(axis=0)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "keywords = [feature_names[i] for i in word_frequencies.argsort()[-10:][::-1]]\n",
        "print(keywords)"
      ],
      "metadata": {
        "id": "JpNf6Mse2ODW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "site_counts = data[\"site_url\"].value_counts()\n",
        "fake_site_counts = data[data[\"label\"]==\"Fake\"][\"site_url\"].value_counts()\n",
        "fake_news_percentage = fake_site_counts / site_counts"
      ],
      "metadata": {
        "id": "gc34f44r25Fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NLP\n",
        "def fakenewsprediction(title, news_source):\n",
        "  title_contains_keyword = any(keyword in title.lower() for keyword in keywords)\n",
        "  if news_source in fake_news_percentage:\n",
        "    source_fake_percentage = fake_news_percentage[news_source]\n",
        "  else:\n",
        "    source_fake_percentage = 0.0\n",
        "\n",
        "  if title_contains_keyword and source_fake_percentage > 0.5:\n",
        "    return \"Fake News\"\n",
        "  else:\n",
        "    return \"Real News\""
      ],
      "metadata": {
        "id": "SzRDZqx627tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = \"Breaking: election week is over\"\n",
        "source_input = \"der-postillon.com\"\n",
        "prediction = fakenewsprediction(text_input,source_input)\n",
        "print(f\"Prediction: {prediction}\")"
      ],
      "metadata": {
        "id": "JVhkKXya17h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "QeDoodOQ3QX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#feature engineering\n",
        "missing_data = data[[\"text\",\"label\"]].isnull().any(axis=1)\n",
        "if missing_data.any():\n",
        "  print(\"Missing Values Found in the Dataset. Handle Missing Data Before Proceeding\")\n",
        "else:\n",
        "  le = LabelEncoder()\n",
        "  data[\"label\"] = le.fit_transform(data[\"label\"])\n",
        "  X = data[\"text\"]\n",
        "  y = data[\"label\"]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
        "  text_feature_extraction = TfidfVectorizer(max_features=5000,stop_words=\"english\")\n",
        "  model = LogisticRegression()\n",
        "  pipeline = Pipeline([\n",
        "      ('tfidf',text_feature_extraction),\n",
        "      ('model',model)\n",
        "  ])\n",
        "  pipeline.fit(X_train,y_train)\n",
        "  y_pred = pipeline.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  print(f\"Accuracy: {accuracy:.2f}\")\n",
        "  def fakenewsprediction(text):\n",
        "    input_data = [text]\n",
        "    prediction = pipeline.predict(input_data)\n",
        "    if prediction[0] == 0:\n",
        "      return \"Real News\"\n",
        "    else:\n",
        "      return \"Fake News\""
      ],
      "metadata": {
        "id": "6CAYAgw27b7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_input = \"Stocks rallied sharply after the Labor Department said nonfarm payrolls rose by 150,000 in October — 20,000 fewer than expected but a difference attributable pretty much completely to the auto strikes, which appear to be over.\"\n",
        "prediction = fakenewsprediction(article_input)\n",
        "print(f\"Prediction: {prediction}\")"
      ],
      "metadata": {
        "id": "_XVko2c-3Rm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Precision, Recall ve F1 Score hesaplama\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "BDrjEM5D1Pp0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Çapraz doğrulama ile doğruluk\n",
        "cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')  # 5 katmanlı çapraz doğrulama\n",
        "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.2f} ± {cv_scores.std():.2f}\")"
      ],
      "metadata": {
        "id": "AW1bLf9V1aYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "OYtFKcIc7p9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[\"title\"]\n",
        "y = data[\"label\"]"
      ],
      "metadata": {
        "id": "ebim7tHb8A6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000,stop_words=\"english\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "cCz_ibv78Eg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "qdVZGYcw8Iq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest_classifier.fit(X_tfidf,y_encoded)"
      ],
      "metadata": {
        "id": "ZqewSXPs8N6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest\n",
        "def fakenewsprediction(title):\n",
        "  title_tfidf = tfidf_vectorizer.transform([title])\n",
        "  prediction = random_forest_classifier.predict(title_tfidf)\n",
        "  predicted_label = label_encoder.inverse_transform(prediction)\n",
        "  return predicted_label[0]"
      ],
      "metadata": {
        "id": "lZEnAMNX7rvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_input = \"Few reasons for optimism after Antony Blinken's diplomatic dash\"\n",
        "prediction = fakenewsprediction(title_input)\n",
        "print(f\"Prediction: {prediction}\")"
      ],
      "metadata": {
        "id": "KV_XOeHa8RhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "5hXFYndd8lIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[\"title\"]\n",
        "y = data[\"label\"]"
      ],
      "metadata": {
        "id": "QE8wLcnt8ueU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000,stop_words=\"english\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)"
      ],
      "metadata": {
        "id": "FwaB8-Ob8x8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)"
      ],
      "metadata": {
        "id": "Xp9wcKdr8zlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf,y_encoded,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "BBFFdsA984M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest_classifier.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "zf4XNeh8856V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = random_forest_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "jcxQ2_ue86b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test,y_pred)"
      ],
      "metadata": {
        "id": "kSW0zJy286s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "sKPIpsec8mdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Doğruluk (Accuracy)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Precision, Recall ve F1 Score\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Sonuçları yazdırma\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "oiUPxDOA3XM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fairlearn"
      ],
      "metadata": {
        "id": "v8-l60vd_QKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference\n",
        "from fairlearn.postprocessing import ThresholdOptimizer\n",
        "from fairlearn.reductions import DemographicParity, EqualizedOdds"
      ],
      "metadata": {
        "id": "rIkEbyau-Bi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[\"title\"]\n",
        "y = data[\"label\"]\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000,stop_words=\"english\")\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf,y_encoded,test_size=0.2,random_state=42)\n",
        "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest_classifier.fit(X_train,y_train)\n",
        "y_pred = random_forest_classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "GDnygvdE_fzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def demographic_parity_difference(y_true,y_pred):\n",
        "  group1_indices = [i for i,y in enumerate(y_true) if y == 0]\n",
        "  group2_indices = [i for i,y in enumerate(y_true) if y == 1]\n",
        "  group1_positive_rate = sum(1 for i in group1_indices if y_pred[i] == 1)/len(group1_indices)\n",
        "  group2_positive_rate = sum(1 for i in group2_indices if y_pred[i] == 1)/len(group2_indices)\n",
        "  dp_diff = abs(group1_positive_rate - group2_positive_rate)\n",
        "  return dp_diff"
      ],
      "metadata": {
        "id": "X8duz6Bf_hQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dp_diff = demographic_parity_difference(y_test,y_pred)\n",
        "print(f\"Demographic Parity Difference: {dp_diff:.4f}\")"
      ],
      "metadata": {
        "id": "FwReol4a_eLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "data = pd.read_csv('cleaned_news_articles.csv')\n",
        "\n",
        "texts = data['text'].tolist()\n",
        "labels = data['label'].tolist()\n",
        "\n",
        "label_map = {label: idx for idx, label in enumerate(set(labels))}\n",
        "labels = [label_map[label] for label in labels]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "qb2N8skD_7ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = NewsDataset(val_texts, val_labels, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_map))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train_epoch(model, data_loader, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    for batch in data_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return total_loss / len(data_loader), correct_predictions / len(data_loader.dataset)\n"
      ],
      "metadata": {
        "id": "wATa6ZE4Amln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model, data_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            logits = outputs.logits\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "            all_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, target_names=label_map.keys())\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return total_loss / len(data_loader), correct_predictions / len(data_loader.dataset), report, accuracy"
      ],
      "metadata": {
        "id": "D0KvWBlqAtzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, loss_fn, optimizer, device)\n",
        "    print(f'Train loss: {train_loss}, accuracy: {train_acc}')\n",
        "\n",
        "    val_loss, val_acc, val_report, val_accuracy = eval_model(model, val_loader, loss_fn, device)\n",
        "    print(f'Validation loss: {val_loss}, accuracy: {val_acc}')\n",
        "    print(f'Validation Accuracy: {val_accuracy}')\n",
        "    print(val_report)"
      ],
      "metadata": {
        "id": "sZ-r7u6GAxuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing the model on validation dataset...\")\n",
        "val_loss, val_acc, val_report, val_accuracy = eval_model(model, val_loader, loss_fn, device)\n",
        "print(f\"Test Accuracy: {val_accuracy}\")\n",
        "print(val_report)"
      ],
      "metadata": {
        "id": "k8t8rntjHh7t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}